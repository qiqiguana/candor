/*
 * This file was automatically generated by EvoSuite
 */

package weka.gui.beans;

import org.junit.Test;
import org.junit.runner.RunWith;
import org.evosuite.junit.EvoSuiteRunner;
import static org.junit.Assert.*;
import org.junit.BeforeClass;
import weka.classifiers.Classifier;
import weka.classifiers.bayes.BayesNet;
import weka.classifiers.bayes.NaiveBayesUpdateable;
import weka.classifiers.functions.SGDText;
import weka.classifiers.meta.FilteredClassifier;
import weka.classifiers.meta.Vote;
import weka.classifiers.trees.J48;
import weka.classifiers.trees.LMT;
import weka.core.Instances;
import weka.gui.beans.BatchClassifierEvent;
import weka.gui.beans.DataSetEvent;

@RunWith(EvoSuiteRunner.class)
public class BatchClassifierEventEvoSuiteTest {

  @BeforeClass 
  public static void initEvoSuiteFramework(){ 
    org.evosuite.Properties.REPLACE_CALLS = true; 
  } 


  @Test
  public void test0()  throws Throwable  {
      NaiveBayesUpdateable naiveBayesUpdateable0 = new NaiveBayesUpdateable();
      BatchClassifierEvent batchClassifierEvent0 = new BatchClassifierEvent((Object) "Class for building and using a 1R classifier; in other words, uses the minimum-error attribute for prediction, discretizing numeric attributes. For more information, see:\n\nR.C. Holte (1993). Very simple classification rules perform well on most commonly used datasets. Machine Learning. 11:63-91.", (Classifier) naiveBayesUpdateable0, (DataSetEvent) null, (DataSetEvent) null, 0, (-1563), (-1563), (-1951));
      NaiveBayesUpdateable naiveBayesUpdateable1 = (NaiveBayesUpdateable)batchClassifierEvent0.getClassifier();
      assertNotNull(naiveBayesUpdateable1);
      assertEquals(-1563, batchClassifierEvent0.getMaxRunNumber());
      assertEquals(9223372036854775807L, batchClassifierEvent0.getGroupIdentifier());
      assertEquals(0, batchClassifierEvent0.getRunNumber());
      assertEquals(-1951, batchClassifierEvent0.getMaxSetNumber());
      assertEquals(-1563, batchClassifierEvent0.getSetNumber());
  }

  @Test
  public void test1()  throws Throwable  {
      Vote vote0 = new Vote();
      DataSetEvent dataSetEvent0 = new DataSetEvent((Object) "The combination rule used.", (Instances) null);
      BatchClassifierEvent batchClassifierEvent0 = new BatchClassifierEvent((Object) "Specify a set of attributes to ignore.  When generating the ranking, Ranker will not evaluate the attributes  in this list. This is specified as a comma seperated list off attribute indexes starting at 1. It can include ranges. Eg. 1,2,5-9,17.", (Classifier) vote0, dataSetEvent0, dataSetEvent0, 0, 1518);
      batchClassifierEvent0.setTestSet(dataSetEvent0);
      assertEquals(1518, batchClassifierEvent0.getMaxSetNumber());
      assertEquals(0, batchClassifierEvent0.getSetNumber());
      assertEquals(1, batchClassifierEvent0.getRunNumber());
      assertEquals(1, batchClassifierEvent0.getMaxRunNumber());
      assertEquals(9223372036854775807L, batchClassifierEvent0.getGroupIdentifier());
  }

  @Test
  public void test2()  throws Throwable  {
      LMT lMT0 = new LMT();
      BatchClassifierEvent batchClassifierEvent0 = new BatchClassifierEvent((Object) "Set splitting criterion based on the residuals of LogitBoost. There are two possible splitting criteria for LMT: the default is to use the C4.5 splitting criterion that uses information gain on the class variable. The other splitting criterion tries to improve the purity in the residuals produces when fitting the logistic regression functions. The choice of the splitting criterion does not usually affect classification accuracy much, but can produce different trees.", (Classifier) lMT0, (DataSetEvent) null, (DataSetEvent) null, 1803, 1803, 1803, 1803);
      int int0 = batchClassifierEvent0.getSetNumber();
      assertEquals(1803, batchClassifierEvent0.getMaxSetNumber());
      assertEquals(1803, batchClassifierEvent0.getRunNumber());
      assertEquals(1803, int0);
      assertEquals(1803, batchClassifierEvent0.getMaxRunNumber());
      assertEquals(9223372036854775807L, batchClassifierEvent0.getGroupIdentifier());
  }

  @Test
  public void test3()  throws Throwable  {
      Vote vote0 = new Vote();
      DataSetEvent dataSetEvent0 = new DataSetEvent((Object) "The combination rule used.", (Instances) null);
      BatchClassifierEvent batchClassifierEvent0 = new BatchClassifierEvent((Object) "Specify a set of attributes to ignore.  When generating the ranking, Ranker will not evaluate the attributes  in this list. This is specified as a comma seperated list off attribute indexes starting at 1. It can include ranges. Eg. 1,2,5-9,17.", (Classifier) vote0, dataSetEvent0, dataSetEvent0, 0, 1518);
      int int0 = batchClassifierEvent0.getMaxSetNumber();
      assertEquals(1, batchClassifierEvent0.getRunNumber());
      assertEquals(0, batchClassifierEvent0.getSetNumber());
      assertEquals(1, batchClassifierEvent0.getMaxRunNumber());
      assertEquals(9223372036854775807L, batchClassifierEvent0.getGroupIdentifier());
      assertEquals(1518, int0);
  }

  @Test
  public void test4()  throws Throwable  {
      SGDText sGDText0 = new SGDText();
      BatchClassifierEvent batchClassifierEvent0 = new BatchClassifierEvent((Object) "The random number seed to be used.", (Classifier) sGDText0, (DataSetEvent) null, (DataSetEvent) null, 0, 0, 0, 0);
      batchClassifierEvent0.setTrainSet((DataSetEvent) null);
      assertEquals(0, batchClassifierEvent0.getMaxSetNumber());
      assertEquals(0, batchClassifierEvent0.getSetNumber());
      assertEquals(0, batchClassifierEvent0.getMaxRunNumber());
      assertEquals(9223372036854775807L, batchClassifierEvent0.getGroupIdentifier());
      assertEquals(0, batchClassifierEvent0.getRunNumber());
  }

  @Test
  public void test5()  throws Throwable  {
      BayesNet bayesNet0 = new BayesNet();
      DataSetEvent dataSetEvent0 = new DataSetEvent((Object) "The base classifier to be used.", (Instances) null);
      BatchClassifierEvent batchClassifierEvent0 = new BatchClassifierEvent((Object) "?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?", (Classifier) bayesNet0, dataSetEvent0, dataSetEvent0, 6, 1162);
      int int0 = batchClassifierEvent0.getRunNumber();
      assertEquals(1162, batchClassifierEvent0.getMaxSetNumber());
      assertEquals(1, batchClassifierEvent0.getMaxRunNumber());
      assertEquals(9223372036854775807L, batchClassifierEvent0.getGroupIdentifier());
      assertEquals(6, batchClassifierEvent0.getSetNumber());
      assertEquals(1, int0);
  }

  @Test
  public void test6()  throws Throwable  {
      NaiveBayesUpdateable naiveBayesUpdateable0 = new NaiveBayesUpdateable();
      BatchClassifierEvent batchClassifierEvent0 = new BatchClassifierEvent((Object) "Class for building and using a 1R classifier; in other words, uses the minimum-error attribute for prediction, discretizing numeric attributes. For more information, see:\n\nR.C. Holte (1993). Very simple classification rules perform well on most commonly used datasets. Machine Learning. 11:63-91.", (Classifier) naiveBayesUpdateable0, (DataSetEvent) null, (DataSetEvent) null, 0, (-1563), (-1563), (-1951));
      long long0 = batchClassifierEvent0.getGroupIdentifier();
      assertEquals(-1563, batchClassifierEvent0.getSetNumber());
      assertEquals(0, batchClassifierEvent0.getRunNumber());
      assertEquals(9223372036854775807L, long0);
      assertEquals(-1951, batchClassifierEvent0.getMaxSetNumber());
      assertEquals(-1563, batchClassifierEvent0.getMaxRunNumber());
  }

  @Test
  public void test7()  throws Throwable  {
      Vote vote0 = new Vote();
      DataSetEvent dataSetEvent0 = new DataSetEvent((Object) "The combination rule used.", (Instances) null);
      BatchClassifierEvent batchClassifierEvent0 = new BatchClassifierEvent((Object) "Specify a set of attributes to ignore.  When generating the ranking, Ranker will not evaluate the attributes  in this list. This is specified as a comma seperated list off attribute indexes starting at 1. It can include ranges. Eg. 1,2,5-9,17.", (Classifier) vote0, dataSetEvent0, dataSetEvent0, 0, 1518);
      DataSetEvent dataSetEvent1 = batchClassifierEvent0.getTrainSet();
      assertEquals(1, batchClassifierEvent0.getRunNumber());
      assertEquals(1518, batchClassifierEvent0.getMaxSetNumber());
      assertEquals(1, batchClassifierEvent0.getMaxRunNumber());
      assertNotNull(dataSetEvent1);
      assertEquals(0, batchClassifierEvent0.getSetNumber());
      assertEquals(9223372036854775807L, batchClassifierEvent0.getGroupIdentifier());
  }

  @Test
  public void test8()  throws Throwable  {
      BayesNet bayesNet0 = new BayesNet();
      FilteredClassifier filteredClassifier0 = new FilteredClassifier();
      DataSetEvent dataSetEvent0 = new DataSetEvent((Object) "The base classifier to be used.", (Instances) null);
      BatchClassifierEvent batchClassifierEvent0 = new BatchClassifierEvent((Object) "?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?", (Classifier) bayesNet0, dataSetEvent0, dataSetEvent0, 6, 1162);
      batchClassifierEvent0.setClassifier((Classifier) filteredClassifier0);
      assertEquals(9223372036854775807L, batchClassifierEvent0.getGroupIdentifier());
      assertEquals(1162, batchClassifierEvent0.getMaxSetNumber());
      assertEquals(1, batchClassifierEvent0.getRunNumber());
      assertEquals(6, batchClassifierEvent0.getSetNumber());
      assertEquals(1, batchClassifierEvent0.getMaxRunNumber());
  }

  @Test
  public void test9()  throws Throwable  {
      NaiveBayesUpdateable naiveBayesUpdateable0 = new NaiveBayesUpdateable();
      BatchClassifierEvent batchClassifierEvent0 = new BatchClassifierEvent((Object) "Class for building and using a 1R classifier; in other words, uses the minimum-error attribute for prediction, discretizing numeric attributes. For more information, see:\n\nR.C. Holte (1993). Very simple classification rules perform well on most commonly used datasets. Machine Learning. 11:63-91.", (Classifier) naiveBayesUpdateable0, (DataSetEvent) null, (DataSetEvent) null, 0, (-1563), (-1563), (-1951));
      batchClassifierEvent0.getTestSet();
      assertEquals(0, batchClassifierEvent0.getRunNumber());
      assertEquals(-1951, batchClassifierEvent0.getMaxSetNumber());
      assertEquals(-1563, batchClassifierEvent0.getMaxRunNumber());
      assertEquals(-1563, batchClassifierEvent0.getSetNumber());
      assertEquals(9223372036854775807L, batchClassifierEvent0.getGroupIdentifier());
  }

  @Test
  public void test10()  throws Throwable  {
      J48 j48_0 = new J48();
      DataSetEvent dataSetEvent0 = new DataSetEvent((Object) "The file containing the stopwords (if this is a directory then the default ones are used).", (Instances) null);
      BatchClassifierEvent batchClassifierEvent0 = new BatchClassifierEvent((Object) "Whether pruning is performed.", (Classifier) j48_0, dataSetEvent0, dataSetEvent0, 21, 1790, 0, 41);
      assertEquals(9223372036854775807L, batchClassifierEvent0.getGroupIdentifier());
      
      batchClassifierEvent0.setGroupIdentifier(0L);
      assertEquals(1790, batchClassifierEvent0.getMaxRunNumber());
  }

  @Test
  public void test11()  throws Throwable  {
      NaiveBayesUpdateable naiveBayesUpdateable0 = new NaiveBayesUpdateable();
      BatchClassifierEvent batchClassifierEvent0 = new BatchClassifierEvent((Object) "Class for building and using a 1R classifier; in other words, uses the minimum-error attribute for prediction, discretizing numeric attributes. For more information, see:\n\nR.C. Holte (1993). Very simple classification rules perform well on most commonly used datasets. Machine Learning. 11:63-91.", (Classifier) naiveBayesUpdateable0, (DataSetEvent) null, (DataSetEvent) null, 0, (-1563), (-1563), (-1951));
      int int0 = batchClassifierEvent0.getMaxRunNumber();
      assertEquals(-1951, batchClassifierEvent0.getMaxSetNumber());
      assertEquals(9223372036854775807L, batchClassifierEvent0.getGroupIdentifier());
      assertEquals(-1563, batchClassifierEvent0.getSetNumber());
      assertEquals(0, batchClassifierEvent0.getRunNumber());
      assertEquals((-1563), int0);
  }
}
